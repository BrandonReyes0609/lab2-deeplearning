{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import altair as alt \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(n_features, n_neurons, n_output): \n",
    "\n",
    "    np.random.seed(100)\n",
    "    W1 = np.random.uniform(size = (n_features, n_neurons))\n",
    "    b1 = np.random.uniform(size = (1, n_neurons))\n",
    "\n",
    "    W2 = np.random.uniform(size = (n_neurons, n_output))\n",
    "    b2 = np.random.uniform(size = (1, n_output))\n",
    "\n",
    "    return {\n",
    "        \"W1\" : W1 \n",
    "        , \"b1\" : b1 \n",
    "        , \"W2\" : W2\n",
    "        , \"b2\" : b2 \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(W, X, b): \n",
    "    return (X @ W)+ b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_func(Z): \n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cost_function(A, y): \n",
    "#    return (np.mean(np.power(A - y, 2)))/2 \n",
    "\n",
    "\n",
    "#def cost_function_cross_entropy(y_pred, y_true):\n",
    "#    \"\"\"\n",
    "#    Calcula la función de pérdida de entropía cruzada binaria.\n",
    "#    Parámetros:\n",
    "#        y_pred: numpy array con las predicciones (valores entre 0 y 1)\n",
    "#        y_true: numpy array con las etiquetas reales (0 o 1)\n",
    "#    Retorna:\n",
    "#        El valor promedio de la pérdida.\n",
    "#    \"\"\"\n",
    "#    epsilon = 1e-12  # para evitar log(0)\n",
    "#    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "#    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "#    return loss\n",
    "\n",
    "\n",
    "def cost_function_cross_entropy(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calcula la entropía cruzada binaria.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-12\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W1, W2, b1, b2): \n",
    "    Z1 = linear_function(W1, X, b1)\n",
    "    S1 = sigmoid_func(Z1)\n",
    "    Z2 = linear_function(W2, S1, b2)\n",
    "    S2 = sigmoid_func(Z2)\n",
    "    return np.where(S2 >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_parameters(n_input, n_hidden, n_output):\n",
    "    w1 = np.random.randn(n_input, n_hidden)\n",
    "    b1 = np.zeros((1, n_hidden))\n",
    "    w2 = np.random.randn(n_hidden, n_output)\n",
    "    b2 = np.zeros((1, n_output))\n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(X, y, w1, b1, w2, b2, learning_rate=0.01, epochs=1000):\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward\n",
    "        z1 = np.dot(X, w1) + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = np.dot(a1, w2) + b2\n",
    "        a2 = sigmoid(z2)\n",
    "\n",
    "        # Loss\n",
    "        loss = cost_function_cross_entropy(a2, y)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        # Backward\n",
    "        delta2 = a2 - y\n",
    "        delta1 = np.dot(delta2, w2.T) * sigmoid_derivative(z1)\n",
    "\n",
    "        # Update\n",
    "        w2 -= learning_rate * np.dot(a1.T, delta2)\n",
    "        b2 -= learning_rate * np.sum(delta2, axis=0, keepdims=True)\n",
    "        w1 -= learning_rate * np.dot(X.T, delta1)\n",
    "        b1 -= learning_rate * np.sum(delta1, axis=0, keepdims=True)\n",
    "\n",
    "    return w1, b1, w2, b2, loss_list\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
